{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries to be used in the exercise\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the files in the folder I´m working in. This will help me to check that I have the right files to load.\n",
    "print(os.listdir()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload the files\n",
    "df_flights = pd.read_csv('Customer Flight Activity.csv' , sep=',')\n",
    "df_loyalty = pd.read_csv('Customer Loyalty History.csv' , sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the construccion of each dataframe\n",
    "print(df_flights.info())\n",
    "print(df_loyalty.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify the index of the dataframes is a custom index or a predefined numeric index\n",
    "print(df_flights.index)\n",
    "print(df_loyalty.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displays the first few rows of the dataframes so its structure can be checked\n",
    "display(df_flights.head())\n",
    "display(df_loyalty.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the columns names are correct\n",
    "print(df_flights.columns)\n",
    "print(df_loyalty.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise column names in both dataframes, remove blank spaces, convert everything to lower case and replace spaces with underscores\n",
    "df_flights.columns = df_flights.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "df_loyalty.columns = df_loyalty.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "print(df_flights.columns)\n",
    "print(df_loyalty.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show how many unique values there are in each column of the dataframes\n",
    "print(\"Number of unique values in Customer Flight Analysis:\")\n",
    "print(df_flights.nunique())\n",
    "\n",
    "print(\"Number of unique values in Customer Loyalty History:\")\n",
    "print(df_loyalty.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique values in columm year:\", df_flights['year'].unique())\n",
    "print(\"unique values in columm month:\", df_flights['month'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check all the duplicated rows and count how many there are\n",
    "print(df_flights.duplicated().sum())   #means that there are 1864 duplicated rows que the same values.\n",
    "print(df_loyalty.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flights[df_flights.duplicated(keep=False)].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates that are exactly the same, removing the extra copies if all columns are the same\n",
    "#and reset the index to avoid gaps after removing duplicates\n",
    "df_flights.drop_duplicates(inplace=True)\n",
    "df_flights.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code to check that the duplicates have been removed correctly. If it returns 0, there are no exact matches.\n",
    "print(df_flights.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To manage duplicates with differences in some columns, we search for records that have the same loyalty_number, year and month, \n",
    "#but with different values in other columns.\n",
    "df_flights[df_flights.duplicated(subset=['loyalty_number', 'year', 'month'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge duplicate values\n",
    "df_flights = df_flights.groupby(['loyalty_number', 'year', 'month']).agg({\n",
    "    \"flights_booked\": \"sum\",\n",
    "    \"flights_with_companions\": \"sum\",\n",
    "    \"total_flights\": \"sum\",\n",
    "    \"distance\": \"sum\",\n",
    "    \"points_accumulated\": \"sum\",\n",
    "    \"points_redeemed\": \"sum\",\n",
    "    \"dollar_cost_points_redeemed\": \"sum\"}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select another option, like keeping only the rows with the most points. The code will be:\n",
    "#df_flights = df_flights.sort_values(by='points_accumulated', ascending=False).drop_duplicates(subset=['loyalty_number', 'year', 'month'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_flights.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am interested in seeing the unique values to test my hypothesis, even though we already know that there are no duplicates in the customer loyalty history.\n",
    "text_columns = df_loyalty.select_dtypes(include=['object']).columns\n",
    "for column_object in text_columns:\n",
    "    print(f\"The singles values of the column {column_object} are:\")\n",
    "    print(df_loyalty[column_object].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The country column has only one value, which does not matter for me, so I will delete it.\n",
    "df_loyalty.drop(columns=['country'], inplace=True)\n",
    "print(df_loyalty.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid errors in further analysis, I will normalise columns with categorical values: gender, education, marital_status, loyalty_card and enrolment_type.\n",
    "columns_to_standar = ['gender','education', 'marital_status', 'loyalty_card', 'enrollment_type']\n",
    "df_loyalty[columns_to_standar] = df_loyalty[columns_to_standar].apply(lambda x: x.str.strip().str.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_standar:\n",
    "    print(f\"The singles values normalise of the column {column} are: {df_loyalty[column].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have finished handling duplicates, we move on to managing nulls. \n",
    "#We have already seen that customer flight activity has no nulls, so we focus on customer loyalty history.\n",
    "#First, we must see where there are nulls so we can decide how to deal with them.\n",
    "df_loyalty.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can calculate the percentage or make a bar chart to get an idea of the amount of nulls in the columns involved.\n",
    "columns_with_nulls = ['salary', 'cancellation_year', 'cancellation_month']\n",
    "nulls_ratio = np.round(df_loyalty[columns_with_nulls].isnull().mean()*100, 2)\n",
    "print(nulls_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=nulls_ratio.index, y=nulls_ratio.values)\n",
    "plt.ylabel(\"% of null values\")\n",
    "plt.title(\"Map of null values in Salary, Cancellation Year and Cancellation Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also run some basic statistics to better understand how the data's distributed or to help identify problems.\n",
    "df_loyalty[['salary', 'cancellation_year', 'cancellation_month']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_nulls = ['salary', 'cancellation_year', 'cancellation_month']\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df_loyalty[columns_with_nulls].isnull(), cmap='Blues', cbar=False, yticklabels=False)\n",
    "plt.title(\"Map of null values in Salary, Cancellation Year and Cancellation Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada barra de representa a un cliente,en oscuro con valor nulo y el claro con valor real. Salary tiene los valores nulos muy dispersos, por lo que no podemos considerar que sigan un patrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Planteamos la hipotesis de que los clientes con valores nulos en cancellation year y cancellation month no son errores, si no que son clientes que siguen siendo activos en el porgrama de fidelidad.\n",
    "cancelled_clients = df_loyalty[['cancellation_year', 'cancellation_month']].notnull().all(axis=1).value_counts()\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"nulls\", \"active\"], cancelled_clients.values)\n",
    "plt.xlabel(\"membership\")\n",
    "plt.ylabel(\"number of members\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=df_loyalty['cancellation_year'].isnull(), y=df_loyalty['clv'])\n",
    "plt.xticks([0, 1], [\"unsubscrib members\", \"Active members\"])\n",
    "plt.ylabel(\"Customer Lifetime Value (CLV)\")\n",
    "plt.xlabel(\"Membership Status\")\n",
    "plt.title(\"Distribution of CLV between active and deleted customers\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_clv_cancelled = df_loyalty[df_loyalty[['cancellation_year', 'cancellation_month']].notnull().all(axis=1)]['clv'].mean()\n",
    "\n",
    "#mean_clv_active = df_loyalty[df_loyalty[['cancellation_year', 'cancellation_month']].isnull().any(axis=1)]['clv'].mean()\n",
    "\n",
    "#mean_clv_cancelled, mean_clv_active\n",
    "\n",
    "(8131.776768263183, 7968.7647402862995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We replace null values with 0 to avoid problems with further analysis. Always remember that 0 means that the client is still active.\n",
    "df_loyalty['cancellation_year'] = df_loyalty['cancellation_year'].fillna(0)\n",
    "df_loyalty['cancellation_month'] = df_loyalty['cancellation_month'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We check that the replacements have been executed correctly.\n",
    "df_loyalty['cancellation_year'] = df_loyalty['cancellation_year'].astype(int)\n",
    "df_loyalty['cancellation_month'] = df_loyalty['cancellation_month'].astype(int)\n",
    "df_loyalty[['cancellation_year', 'cancellation_month']].info()\n",
    "df_loyalty[['cancellation_year', 'cancellation_month']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_salaries = (df_loyalty['salary'] < 0).sum()\n",
    "print(negative_salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty[df_loyalty['salary'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty.loc[df_loyalty['salary'] < 0, 'salary'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_negative_salaries = (df_loyalty['salary'] < 0).sum()\n",
    "print(new_negative_salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df_loyalty['salary'].dropna(), bins=30, edgecolor='black', alpha=0.7, log=True)\n",
    "plt.title(\"Distribución de Salary\")\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x=df_loyalty['salary'])\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.title(\"Possible outliers in salary distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To see how we can manage the null values in the salary column, we are going to make a series of comparisons with columns in the same table. \n",
    "#This will show us their relationship and whether they follow a pattern.\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x='education', y='salary', data=df_loyalty)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Distribution of Salary by Education Level\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='city', y='salary', data=df_loyalty)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Salary Distribution by City \")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 6))\n",
    "sns.boxplot(x='postal_code', y='salary', data=df_loyalty)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Salary Distribution by Postal Code \")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.scatterplot(x='salary', y='clv', data=df_loyalty, alpha=0.5)\n",
    "plt.xlabel(\"Salary\")\n",
    "plt.ylabel(\"CLV\")\n",
    "plt.title(\"Salary and CLV ratios\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x='enrollment_type', y='salary', data=df_loyalty, estimator=np.median)\n",
    "plt.title(\"Median Salary by Membership\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To substitute missing values we will use IterativeImputer as it is the most complete method to replace null values.\n",
    "#These models cannot use categorical values so we will map relevant columns such as education or postal code to numerical ones before executing this technique.\n",
    "education_mapping ={'High School or Below': 0,\n",
    "                    'college': 1,\n",
    "                    'bachelor': 2,\n",
    "                    'master': 3,\n",
    "                    'doctor': 4}\n",
    "df_loyalty['education_number'] = df_loyalty['education'].map(education_mapping)\n",
    "\n",
    "df_loyalty['postal_code_number'], _ = df_loyalty['postal_code'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty[['education', 'education_number', 'postal_code', 'postal_code_number']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_loyalty.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty[['salary', 'clv']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colums_imputer = ['salary', 'clv', 'education_number', 'postal_code_number']\n",
    "imputer = IterativeImputer(max_iter=100, random_state=42)\n",
    "df_loyalty[colums_imputer] = imputer.fit_transform(df_loyalty[colums_imputer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty['salary'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty[['salary', 'clv']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove the columns that we have converted to numerical columns as we no longer need them.\n",
    "df_loyalty.drop(columns=['education_number', 'postal_code_number'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will join the dataframes using the loyalty_number column. \n",
    "#We want to keep all the clients of df_loyalty and add the data of df_flights. So we will make a merge left join.\n",
    "df_merged = df_loyalty.merge(df_flights, on='loyalty_number', how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the new clean dataset to a CSV file\n",
    "df_merged.to_csv(\"airline_loyalty_programme.csv\", index=False)\n",
    "print(os.listdir()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are columns that for the visualisation phase we don't care if they are joined, so let's proceed to join them.\n",
    "df_merged['enrollment_date'] = pd.to_datetime(df_merged['enrollment_year'].astype(str) + '-' + df_merged['enrollment_month'].astype(str) + '-01', format=\"%Y-%m-%d\")\n",
    "df_merged =df_merged.drop(columns=['enrollment_year', 'enrollment_month'])\n",
    "col_position = df_merged.columns.get_loc('cancellation_year')\n",
    "df_merged.insert(col_position, 'enrollment_date', df_merged.pop('enrollment_date'))\n",
    "df_merged = df_merged.set_index('loyalty_number')\n",
    "df_merged.sample(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 1: Distribution of the number of flights booked per month during each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_month_and_year =df_flights.groupby(['year', 'month'])['flights_booked'].sum().reset_index()\n",
    "print(flights_month_and_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_month_and_year =df_flights.groupby(['year', 'month'])['flights_booked'].sum().reset_index()\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.lineplot(x='month', y='flights_booked', hue='year', data=flights_month_and_year, marker=\"o\", linewidth=2, markersize=6)\n",
    "plt.title(\"Distribution of flights booked per month and year\")\n",
    "plt.xticks(ticks=range(1, 13))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Flights booked\")\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_month_and_year =df_flights.groupby(['year', 'month'])['flights_booked'].sum().reset_index()\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x='month', y='flights_booked', hue='year', data=flights_month_and_year)\n",
    "plt.title(\"Distribution of flights booked per month and year\")\n",
    "plt.xticks(ticks=range(1, 13))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Flights booked\")\n",
    "plt.legend(title='Year')\n",
    "plt.grid(True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 2: Is there a connection between flight distance and points accumulated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=\"distance\", y=\"points_accumulated\", hue=\"loyalty_card\", data= df_merged, marker=\"o\", palette=\"rocket\")\n",
    "plt.xlabel(\"Flight´s distance\")\n",
    "plt.ylabel(\"Accumulated points\")\n",
    "plt.title(\"Ratio between flight distance and accumulated points\")\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"distance\", y=\"points_accumulated\", hue=\"loyalty_card\", data=df_merged, markers=\"o\", height=6, aspect=1.5, palette=\"rocket\", scatter_kws={\"alpha\": 0.3, \"s\": 50}, line_kws={\"linewidth\":3})\n",
    "plt.xlabel(\"Flight´s distance\")\n",
    "plt.ylabel(\"Accumulated points\")\n",
    "plt.title(\"Ratio between flight distance and accumulated points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(x=\"distance\", y=\"points_accumulated\", hue=\"loyalty_card\", data= df_merged, marker=\"o\", palette=\"dark:#5A9_r\")\n",
    "plt.xlabel(\"Flight´s distance\")\n",
    "plt.ylabel(\"Accumulated points\")\n",
    "plt.title(\"Ratio between flight distance and accumulated points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 3: What is the distribution of clients by province and state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_province = df_loyalty[\"province\"].value_counts()\n",
    "print(members_province)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "members_province.plot(kind=\"bar\", color=\"pink\", edgecolor=\"purple\", linewidth=3)\n",
    "plt.xlabel(\"Province\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Number of clients\")\n",
    "plt.title(\"Ratio clients by province\")\n",
    "plt.grid(True, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "members_percentage = (members_province / members_province.sum()) * 100\n",
    "members_percentage = members_percentage.sort_values(ascending=True)\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x=members_percentage, y=members_percentage.index, palette=\"Purples_r\")\n",
    "ax.bar_label(ax.containers[0], fmt=\"%.1f%%\", padding=5, fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Percentage of Clients\")\n",
    "plt.ylabel(\"Province\")\n",
    "plt.title(\"Percentage of Clients by Province\")\n",
    "plt.xlim(0, max(members_percentage) + 5) \n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 4: Compare the average salary by education level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_by_education = df_loyalty.groupby(\"education\")[\"salary\"].mean().round(2).sort_values()\n",
    "print(salary_by_education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = salary_by_education.reset_index() \n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=df_salary, x=\"education\", y=\"salary\", color=\"#6C8E68\", edgecolor=\"#8e686e\", linewidth=5)\n",
    "ax.bar_label(ax.containers[0], fmt=\"%.2f\", fontsize=10, color=\"black\", padding=5)\n",
    "plt.xlabel(\"Education\")\n",
    "plt.ylabel(\"Average Salary\")\n",
    "plt.title(\"A Comparison of Average Salaries by Educational Level\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.boxplot(x=df_loyalty[\"education\"], y=df_loyalty[\"salary\"], \n",
    "            boxprops={\"facecolor\": \"#6C8E68\", \"edgecolor\": \"#8E686E\", \"linewidth\": 2},\n",
    "            medianprops={\"color\": \"#403033\", \"linewidth\": 2},  \n",
    "            whiskerprops={\"color\": \"#8E686E\", \"linewidth\": 2}, \n",
    "            capprops={\"color\": \"#8E686E\", \"linewidth\": 2},\n",
    "            flierprops={\"marker\": \"o\", \"color\": \"#8E686E\", \"alpha\": 0.5})  \n",
    "plt.xlabel(\"Educational Attainment\")\n",
    "plt.ylabel(\"Income\")\n",
    "plt.title(\"Income and Educational Attainment Structure\")\n",
    "plt.grid(True, alpha=0.5, linestyle=\"--\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to see the same graph only with the college data in order to see it properly.\n",
    "df_college = df_loyalty[df_loyalty[\"education\"] == \"college\"]\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.boxplot(y=df_college[\"salary\"], \n",
    "            boxprops={\"facecolor\": \"#6C8E68\", \"edgecolor\": \"#8E686E\", \"linewidth\": 2},\n",
    "            medianprops={\"color\": \"#403033\", \"linewidth\": 2},\n",
    "            whiskerprops={\"color\": \"#8E686E\", \"linewidth\": 2},  # Bigotes\n",
    "            capprops={\"color\": \"#8E686E\", \"linewidth\": 2},\n",
    "            flierprops={\"marker\": \"o\", \"markerfacecolor\": \"#8E686E\", \"alpha\": 0.5})\n",
    "plt.ylabel(\"Income\")\n",
    "plt.title(\"Income Distribution for College Education Level\")\n",
    "plt.grid(True, alpha=0.5, linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_loyalty[\"education\"] = df_loyalty[\"education\"].str.strip().str.lower()\n",
    "plt.figure(figsize=(10, 8))  \n",
    "sns.histplot(data=df_loyalty, y=\"salary\", hue=\"education\", bins=40, kde=True, alpha=0.3, palette=\"mako\", edgecolor=\"black\", multiple=\"layer\", stat=\"count\")\n",
    "plt.ylabel(\"Salary\")\n",
    "plt.xlabel(\"Number of clients\")\n",
    "plt.title(\"Salary by educational level\")\n",
    "plt.legend(title=\"educational level\", labels=df_loyalty[\"education\"].unique(), loc=\"upper right\")\n",
    "plt.grid(True, alpha=0.5, linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 5: What is the percentage of clients for each type of loyalty card?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loyalty_counts = df_loyalty[\"loyalty_card\"].value_counts(normalize=True) * 100\n",
    "print(loyalty_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "colors = [\"#dbb770\", \"#db7094\", \"#db8270\", \"gold\"]\n",
    "wedges, texts, autotexts = plt.pie(loyalty_counts, labels=loyalty_counts.index, autopct=\"%1.1f%%\", colors=colors, startangle=140, wedgeprops={\"edgecolor\": \"#f1debd\", \"linewidth\": 2.5})\n",
    "for text, color in zip(texts, colors):\n",
    "    text.set_text(text.get_text().upper()) \n",
    "    text.set_color(color) \n",
    "    text.set_fontsize(12) \n",
    "plt.title(\"Customer Distribution by Type of Loyalty Card\", pad=30)\n",
    "plt.axis(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('airline_loyalty_programme.csv' , sep=',')\n",
    "\n",
    "# Confirmar que los datos se han cargado correctamente\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables = df.select_dtypes(include=\"number\").columns\n",
    "correlation_data = df[numerical_variables].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_data, annot=True, cmap='flare', fmt='.2f', linewidths=.5)\n",
    "plt.title('Correlation Between the Variables', pad=20, fontsize=14)\n",
    "plt.xticks(rotation=45, ha=\"right\") \n",
    "plt.yticks(rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ❓ Question 6: How are clients distributed according to marital status and gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marital_gender_counts = df_loyalty.groupby([\"marital_status\", \"gender\"]).size().unstack()\n",
    "print(marital_gender_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "marital_gender_counts.plot(kind=\"bar\", figsize=(10, 6), color=[\"#c7c4ff\", \"#c4dfff\"], edgecolor=\"#ffc7c4\")\n",
    "plt.xlabel(\"Marital Status\")\n",
    "plt.ylabel(\"Number of clients\")\n",
    "plt.title(\"Distribution of Clients by Marital Status and Gender\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Gender\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_counts = df_loyalty[\"marital_status\"].value_counts()\n",
    "plt.figure(figsize=(6, 4))\n",
    "explode = [0.05] * len(marital_counts)\n",
    "wedges, texts, autotexts = plt.pie(marital_counts, labels=marital_counts.index, autopct=\"%1.1f%%\", colors=plt.cm.Pastel2.colors, startangle=140, explode=explode)\n",
    "for text, color in zip(texts, colors):\n",
    "    text.set_text(text.get_text().upper()) \n",
    "    text.set_color(color) \n",
    "    text.set_fontsize(12) \n",
    "plt.title(\"Customers by Marital Status\", pad=30)\n",
    "plt.axis(\"equal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
